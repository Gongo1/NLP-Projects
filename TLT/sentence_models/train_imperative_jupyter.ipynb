{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Train Model\n",
    "\n",
    "After running the dataset through the cross validation, we can start training our model\n",
    "Using sklearn we're doing an 80-20 split of our data. We start by importing all the packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block defines all the parameters that we'll need to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params():\n",
    "\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"binary:logistic\"\n",
    "    params[\"eta\"] = 0.1\n",
    "    params[\"subsample\"] = 0.7\n",
    "    params[\"colsample_bytree\"] = 0.7\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 5\n",
    "    params[\"eval_metric\"] = \"logloss\"\n",
    "    plst = list(params.items())\n",
    "\n",
    "    return plst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the training data\n",
    "data = pd.read_csv('data/training_data.csv') #PROVIDE: path to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'label' #Provide: name of the label column\n",
    "data = data.drop(\"text\", axis = 1) #Provide: name of the column containing the data\n",
    "\n",
    "y_train = data[[y_col]]\n",
    "x_train = data.drop(y_col, axis=1)\n",
    "early_stopping = 10\n",
    "params = get_params()\n",
    "num_round = 106 #Provide: based on the cross validation we know the optimum number of training rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our variables, we can go ahead and split our data into testing & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)\n",
    "xg_train = xgb.DMatrix(xTrain, label=yTrain)\n",
    "xg_test = xgb.DMatrix(xTest, label=yTest)\n",
    "\n",
    "#We create a watchlist to visualize the training in real-time\n",
    "watchlist = [(xg_test, 'eval'), (xg_train, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:0.629622\ttrain-logloss:0.609736\n",
      "[1]\teval-logloss:0.56519\ttrain-logloss:0.537478\n",
      "[2]\teval-logloss:0.511697\ttrain-logloss:0.476775\n",
      "[3]\teval-logloss:0.461869\ttrain-logloss:0.4247\n",
      "[4]\teval-logloss:0.423426\ttrain-logloss:0.381331\n",
      "[5]\teval-logloss:0.392358\ttrain-logloss:0.34235\n",
      "[6]\teval-logloss:0.362308\ttrain-logloss:0.309938\n",
      "[7]\teval-logloss:0.338575\ttrain-logloss:0.280724\n",
      "[8]\teval-logloss:0.312857\ttrain-logloss:0.254895\n",
      "[9]\teval-logloss:0.294335\ttrain-logloss:0.232348\n",
      "[10]\teval-logloss:0.277842\ttrain-logloss:0.211481\n",
      "[11]\teval-logloss:0.264802\ttrain-logloss:0.193669\n",
      "[12]\teval-logloss:0.251696\ttrain-logloss:0.176952\n",
      "[13]\teval-logloss:0.243955\ttrain-logloss:0.161611\n",
      "[14]\teval-logloss:0.230009\ttrain-logloss:0.148637\n",
      "[15]\teval-logloss:0.220642\ttrain-logloss:0.136935\n",
      "[16]\teval-logloss:0.209052\ttrain-logloss:0.126761\n",
      "[17]\teval-logloss:0.202986\ttrain-logloss:0.117038\n",
      "[18]\teval-logloss:0.191429\ttrain-logloss:0.10846\n",
      "[19]\teval-logloss:0.184888\ttrain-logloss:0.100951\n",
      "[20]\teval-logloss:0.177199\ttrain-logloss:0.093097\n",
      "[21]\teval-logloss:0.173108\ttrain-logloss:0.08661\n",
      "[22]\teval-logloss:0.170748\ttrain-logloss:0.079954\n",
      "[23]\teval-logloss:0.168377\ttrain-logloss:0.074385\n",
      "[24]\teval-logloss:0.162848\ttrain-logloss:0.069763\n",
      "[25]\teval-logloss:0.15463\ttrain-logloss:0.06556\n",
      "[26]\teval-logloss:0.150208\ttrain-logloss:0.061015\n",
      "[27]\teval-logloss:0.147866\ttrain-logloss:0.057435\n",
      "[28]\teval-logloss:0.147751\ttrain-logloss:0.053866\n",
      "[29]\teval-logloss:0.145996\ttrain-logloss:0.050813\n",
      "[30]\teval-logloss:0.139581\ttrain-logloss:0.048126\n",
      "[31]\teval-logloss:0.138429\ttrain-logloss:0.04535\n",
      "[32]\teval-logloss:0.139277\ttrain-logloss:0.042777\n",
      "[33]\teval-logloss:0.135017\ttrain-logloss:0.040629\n",
      "[34]\teval-logloss:0.134277\ttrain-logloss:0.038323\n",
      "[35]\teval-logloss:0.129513\ttrain-logloss:0.03623\n",
      "[36]\teval-logloss:0.128478\ttrain-logloss:0.034334\n",
      "[37]\teval-logloss:0.128995\ttrain-logloss:0.032688\n",
      "[38]\teval-logloss:0.128986\ttrain-logloss:0.030845\n",
      "[39]\teval-logloss:0.124566\ttrain-logloss:0.029455\n",
      "[40]\teval-logloss:0.120019\ttrain-logloss:0.028129\n",
      "[41]\teval-logloss:0.118171\ttrain-logloss:0.026931\n",
      "[42]\teval-logloss:0.11545\ttrain-logloss:0.025811\n",
      "[43]\teval-logloss:0.112762\ttrain-logloss:0.024581\n",
      "[44]\teval-logloss:0.113887\ttrain-logloss:0.023535\n",
      "[45]\teval-logloss:0.114541\ttrain-logloss:0.022511\n",
      "[46]\teval-logloss:0.114913\ttrain-logloss:0.021524\n",
      "[47]\teval-logloss:0.111076\ttrain-logloss:0.020686\n",
      "[48]\teval-logloss:0.107839\ttrain-logloss:0.019828\n",
      "[49]\teval-logloss:0.104623\ttrain-logloss:0.01911\n",
      "[50]\teval-logloss:0.105558\ttrain-logloss:0.018332\n",
      "[51]\teval-logloss:0.102717\ttrain-logloss:0.017623\n",
      "[52]\teval-logloss:0.100559\ttrain-logloss:0.016982\n",
      "[53]\teval-logloss:0.098925\ttrain-logloss:0.016456\n",
      "[54]\teval-logloss:0.09868\ttrain-logloss:0.016456\n",
      "[55]\teval-logloss:0.097898\ttrain-logloss:0.015834\n",
      "[56]\teval-logloss:0.098018\ttrain-logloss:0.015834\n",
      "[57]\teval-logloss:0.098351\ttrain-logloss:0.015834\n",
      "[58]\teval-logloss:0.098047\ttrain-logloss:0.015834\n",
      "[59]\teval-logloss:0.097824\ttrain-logloss:0.015834\n",
      "[60]\teval-logloss:0.095378\ttrain-logloss:0.015314\n",
      "[61]\teval-logloss:0.094994\ttrain-logloss:0.015315\n",
      "[62]\teval-logloss:0.094562\ttrain-logloss:0.015318\n",
      "[63]\teval-logloss:0.094682\ttrain-logloss:0.015317\n",
      "[64]\teval-logloss:0.094883\ttrain-logloss:0.015315\n",
      "[65]\teval-logloss:0.095122\ttrain-logloss:0.015314\n",
      "[66]\teval-logloss:0.094579\ttrain-logloss:0.015318\n",
      "[67]\teval-logloss:0.094487\ttrain-logloss:0.015318\n",
      "[68]\teval-logloss:0.094774\ttrain-logloss:0.015316\n",
      "[69]\teval-logloss:0.094923\ttrain-logloss:0.015315\n",
      "[70]\teval-logloss:0.095154\ttrain-logloss:0.015314\n",
      "[71]\teval-logloss:0.095224\ttrain-logloss:0.015314\n",
      "[72]\teval-logloss:0.095213\ttrain-logloss:0.015314\n",
      "[73]\teval-logloss:0.095451\ttrain-logloss:0.015313\n",
      "[74]\teval-logloss:0.09542\ttrain-logloss:0.015313\n",
      "[75]\teval-logloss:0.09515\ttrain-logloss:0.015314\n",
      "[76]\teval-logloss:0.094895\ttrain-logloss:0.015315\n",
      "[77]\teval-logloss:0.09501\ttrain-logloss:0.015315\n",
      "[78]\teval-logloss:0.093579\ttrain-logloss:0.014905\n",
      "[79]\teval-logloss:0.093346\ttrain-logloss:0.014906\n",
      "[80]\teval-logloss:0.092294\ttrain-logloss:0.014424\n",
      "[81]\teval-logloss:0.092156\ttrain-logloss:0.014425\n",
      "[82]\teval-logloss:0.092673\ttrain-logloss:0.014423\n",
      "[83]\teval-logloss:0.093078\ttrain-logloss:0.014422\n",
      "[84]\teval-logloss:0.092768\ttrain-logloss:0.014422\n",
      "[85]\teval-logloss:0.092937\ttrain-logloss:0.014422\n",
      "[86]\teval-logloss:0.093303\ttrain-logloss:0.014422\n",
      "[87]\teval-logloss:0.093481\ttrain-logloss:0.014423\n",
      "[88]\teval-logloss:0.093738\ttrain-logloss:0.014424\n",
      "[89]\teval-logloss:0.093478\ttrain-logloss:0.014423\n",
      "[90]\teval-logloss:0.093247\ttrain-logloss:0.014422\n",
      "[91]\teval-logloss:0.093526\ttrain-logloss:0.014423\n",
      "[92]\teval-logloss:0.093654\ttrain-logloss:0.014423\n",
      "[93]\teval-logloss:0.093817\ttrain-logloss:0.014424\n",
      "[94]\teval-logloss:0.093815\ttrain-logloss:0.014424\n",
      "[95]\teval-logloss:0.093662\ttrain-logloss:0.014423\n",
      "[96]\teval-logloss:0.093758\ttrain-logloss:0.014424\n",
      "[97]\teval-logloss:0.093622\ttrain-logloss:0.014423\n",
      "[98]\teval-logloss:0.093788\ttrain-logloss:0.014424\n",
      "[99]\teval-logloss:0.093724\ttrain-logloss:0.014424\n",
      "[100]\teval-logloss:0.09381\ttrain-logloss:0.014424\n",
      "[101]\teval-logloss:0.093694\ttrain-logloss:0.014423\n",
      "[102]\teval-logloss:0.093497\ttrain-logloss:0.014423\n",
      "[103]\teval-logloss:0.093317\ttrain-logloss:0.014422\n",
      "[104]\teval-logloss:0.093261\ttrain-logloss:0.014422\n",
      "[105]\teval-logloss:0.093037\ttrain-logloss:0.014422\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(params,\n",
    "                        xg_train,\n",
    "                        num_round,\n",
    "                        watchlist,\n",
    "                        verbose_eval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is complete, we can save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('imperative.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
